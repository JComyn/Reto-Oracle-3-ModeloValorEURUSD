{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from ta import momentum\n",
    "from ta.trend import MACD, ADXIndicator, CCIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.volatility import AverageTrueRange\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv files\n",
    "train_df = pd.read_csv('training_set.csv')\n",
    "test_df = pd.read_csv('testing_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Remove missing values\n",
    "train_df = train_df.dropna()\n",
    "#test_df = test_df.dropna() # We don't have missing values in test_df\n",
    "# We lose 198 rows (5,64%)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "train_df = train_df.drop(['train_idx'], axis=1)\n",
    "train_df = train_df.drop(['Time'], axis=1)\n",
    "\n",
    "test_df = test_df.drop(['test_idx'], axis=1)\n",
    "test_df = test_df.drop(['Time'], axis=1)\n",
    "\n",
    "# Remove outliers\n",
    "# En el análisis exploratorio con apex hemos visto que los valores suelen estar entre 1 y 2 para open high low close\n",
    "# Por tanto, eliminamos los valores que no estén en ese rango, es probable que sean errores de medición.\n",
    "train_df = train_df[(train_df['Open'] > 1) & (train_df['Open'] < 2)]\n",
    "train_df = train_df[(train_df['High'] > 1) & (train_df['High'] < 2)]\n",
    "train_df = train_df[(train_df['Low'] > 1) & (train_df['Low'] < 2)]\n",
    "train_df = train_df[(train_df['Close'] > 1) & (train_df['Close'] < 2)]\n",
    "\n",
    "# 65 rows removed. Counting the previous 198, we have removed 263 rows (7.5% of the original dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ta\\trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "C:\\Users\\comyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ta\\trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "C:\\Users\\comyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ta\\trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "C:\\Users\\comyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ta\\trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>Open_10day_ma</th>\n",
       "      <th>ADX</th>\n",
       "      <th>CCI</th>\n",
       "      <th>BB_upper</th>\n",
       "      <th>BB_lower</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATR_10day_ma</th>\n",
       "      <th>RSI_10day_ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.31258</td>\n",
       "      <td>1.31844</td>\n",
       "      <td>1.31086</td>\n",
       "      <td>1.31648</td>\n",
       "      <td>1807377.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.31667</td>\n",
       "      <td>1.31813</td>\n",
       "      <td>1.31154</td>\n",
       "      <td>1.31396</td>\n",
       "      <td>1995920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.31396</td>\n",
       "      <td>1.31583</td>\n",
       "      <td>1.30864</td>\n",
       "      <td>1.31118</td>\n",
       "      <td>1859100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.31236</td>\n",
       "      <td>1.31415</td>\n",
       "      <td>1.31068</td>\n",
       "      <td>1.31175</td>\n",
       "      <td>192381.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.31811</td>\n",
       "      <td>1.32186</td>\n",
       "      <td>1.31547</td>\n",
       "      <td>1.31927</td>\n",
       "      <td>2003765.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>1.18053</td>\n",
       "      <td>1.18221</td>\n",
       "      <td>1.17498</td>\n",
       "      <td>1.17689</td>\n",
       "      <td>220609.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.321066</td>\n",
       "      <td>-0.011345</td>\n",
       "      <td>-0.010300</td>\n",
       "      <td>1.188540</td>\n",
       "      <td>48.127098</td>\n",
       "      <td>-123.552963</td>\n",
       "      <td>1.222887</td>\n",
       "      <td>1.171151</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>28.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>1.17684</td>\n",
       "      <td>1.17756</td>\n",
       "      <td>1.17441</td>\n",
       "      <td>1.17474</td>\n",
       "      <td>18855.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.261274</td>\n",
       "      <td>-0.011657</td>\n",
       "      <td>-0.010572</td>\n",
       "      <td>1.186527</td>\n",
       "      <td>49.467339</td>\n",
       "      <td>-132.156197</td>\n",
       "      <td>1.219323</td>\n",
       "      <td>1.169895</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>28.643269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>1.17473</td>\n",
       "      <td>1.17973</td>\n",
       "      <td>1.17165</td>\n",
       "      <td>1.17913</td>\n",
       "      <td>227861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.340247</td>\n",
       "      <td>-0.011418</td>\n",
       "      <td>-0.010741</td>\n",
       "      <td>1.184639</td>\n",
       "      <td>50.850432</td>\n",
       "      <td>-113.648305</td>\n",
       "      <td>1.215982</td>\n",
       "      <td>1.169426</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>29.553814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>1.17914</td>\n",
       "      <td>1.18296</td>\n",
       "      <td>1.17567</td>\n",
       "      <td>1.17824</td>\n",
       "      <td>255729.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.793416</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>-0.010827</td>\n",
       "      <td>1.184011</td>\n",
       "      <td>51.305369</td>\n",
       "      <td>-89.649698</td>\n",
       "      <td>1.213615</td>\n",
       "      <td>1.168541</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>30.431084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>1.17825</td>\n",
       "      <td>1.17877</td>\n",
       "      <td>1.16758</td>\n",
       "      <td>1.17069</td>\n",
       "      <td>316034.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.559757</td>\n",
       "      <td>-0.011454</td>\n",
       "      <td>-0.010952</td>\n",
       "      <td>1.183346</td>\n",
       "      <td>52.205964</td>\n",
       "      <td>-125.366007</td>\n",
       "      <td>1.210828</td>\n",
       "      <td>1.167106</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>29.847554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3246 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open     High      Low    Close     Volume  label        RSI  \\\n",
       "0     1.31258  1.31844  1.31086  1.31648  1807377.0      0        NaN   \n",
       "1     1.31667  1.31813  1.31154  1.31396  1995920.0      1        NaN   \n",
       "2     1.31396  1.31583  1.30864  1.31118  1859100.0      1        NaN   \n",
       "3     1.31236  1.31415  1.31068  1.31175   192381.0      1        NaN   \n",
       "5     1.31811  1.32186  1.31547  1.31927  2003765.0      1        NaN   \n",
       "...       ...      ...      ...      ...        ...    ...        ...   \n",
       "3504  1.18053  1.18221  1.17498  1.17689   220609.0      1  26.321066   \n",
       "3505  1.17684  1.17756  1.17441  1.17474    18855.0      0  25.261274   \n",
       "3506  1.17473  1.17973  1.17165  1.17913   227861.0      0  31.340247   \n",
       "3507  1.17914  1.18296  1.17567  1.17824   255729.0      0  30.793416   \n",
       "3508  1.17825  1.17877  1.16758  1.17069   316034.0      0  26.559757   \n",
       "\n",
       "          MACD  MACD_signal  Open_10day_ma        ADX         CCI  BB_upper  \\\n",
       "0          NaN          NaN            NaN   0.000000         NaN       NaN   \n",
       "1          NaN          NaN            NaN   0.000000         NaN       NaN   \n",
       "2          NaN          NaN            NaN   0.000000         NaN       NaN   \n",
       "3          NaN          NaN            NaN   0.000000         NaN       NaN   \n",
       "5          NaN          NaN            NaN   0.000000         NaN       NaN   \n",
       "...        ...          ...            ...        ...         ...       ...   \n",
       "3504 -0.011345    -0.010300       1.188540  48.127098 -123.552963  1.222887   \n",
       "3505 -0.011657    -0.010572       1.186527  49.467339 -132.156197  1.219323   \n",
       "3506 -0.011418    -0.010741       1.184639  50.850432 -113.648305  1.215982   \n",
       "3507 -0.011172    -0.010827       1.184011  51.305369  -89.649698  1.213615   \n",
       "3508 -0.011454    -0.010952       1.183346  52.205964 -125.366007  1.210828   \n",
       "\n",
       "      BB_lower       ATR  ATR_10day_ma  RSI_10day_ma  \n",
       "0          NaN  0.000000           NaN           NaN  \n",
       "1          NaN  0.000000           NaN           NaN  \n",
       "2          NaN  0.000000           NaN           NaN  \n",
       "3          NaN  0.000000           NaN           NaN  \n",
       "5          NaN  0.000000           NaN           NaN  \n",
       "...        ...       ...           ...           ...  \n",
       "3504  1.171151  0.007568      0.007360     28.727000  \n",
       "3505  1.169895  0.007252      0.007390     28.643269  \n",
       "3506  1.169426  0.007311      0.007405     29.553814  \n",
       "3507  1.168541  0.007310      0.007418     30.431084  \n",
       "3508  1.167106  0.007587      0.007439     29.847554  \n",
       "\n",
       "[3246 rows x 17 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering (add new features)\n",
    "\n",
    "# Calculate RSI\n",
    "train_df['RSI'] = momentum.RSIIndicator(train_df['Close']).rsi()\n",
    "\n",
    "test_df['RSI'] = momentum.RSIIndicator(test_df['Close']).rsi()\n",
    "\n",
    "# Calculate MACD\n",
    "macd = MACD(train_df['Close'])\n",
    "train_df['MACD'] = macd.macd()\n",
    "train_df['MACD_signal'] = macd.macd_signal()\n",
    "\n",
    "macd = MACD(test_df['Close'])\n",
    "test_df['MACD'] = macd.macd()\n",
    "test_df['MACD_signal'] = macd.macd_signal()\n",
    "\n",
    "# Calculate 10-day moving average of Open price\n",
    "train_df['Open_10day_ma'] = train_df['Open'].rolling(window=10).mean()\n",
    "\n",
    "test_df['Open_10day_ma'] = test_df['Open'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate Average Directional Index (ADX)\n",
    "adx = ADXIndicator(train_df['High'], train_df['Low'], train_df['Close'])\n",
    "train_df['ADX'] = adx.adx()\n",
    "\n",
    "adx = ADXIndicator(test_df['High'], test_df['Low'], test_df['Close'])\n",
    "test_df['ADX'] = adx.adx()\n",
    "\n",
    "# Calculate Commodity Channel Index (CCI)\n",
    "cci = CCIIndicator(train_df['High'], train_df['Low'], train_df['Close'])\n",
    "train_df['CCI'] = cci.cci()\n",
    "\n",
    "cci = CCIIndicator(test_df['High'], test_df['Low'], test_df['Close'])\n",
    "test_df['CCI'] = cci.cci()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "bb = BollingerBands(train_df['Close'], window=20, window_dev=2)\n",
    "train_df['BB_upper'] = bb.bollinger_hband()\n",
    "train_df['BB_lower'] = bb.bollinger_lband()\n",
    "\n",
    "bb = BollingerBands(test_df['Close'], window=20, window_dev=2)\n",
    "test_df['BB_upper'] = bb.bollinger_hband()\n",
    "test_df['BB_lower'] = bb.bollinger_lband()\n",
    "\n",
    "\n",
    "# Calculate Average True Range (ATR)\n",
    "atr = AverageTrueRange(high=train_df['High'], low=train_df['Low'], close=train_df['Close'], window=14)\n",
    "train_df['ATR'] = atr.average_true_range()\n",
    "\n",
    "atr = AverageTrueRange(high=test_df['High'], low=test_df['Low'], close=test_df['Close'], window=14)\n",
    "test_df['ATR'] = atr.average_true_range()\n",
    "\n",
    "# Calculate 10-day moving average of ATR\n",
    "train_df['ATR_10day_ma'] = train_df['ATR'].rolling(window=10).mean()\n",
    "\n",
    "test_df['ATR_10day_ma'] = test_df['ATR'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate 10-day moving average of RSI\n",
    "train_df['RSI_10day_ma'] = train_df['RSI'].rolling(window=10).mean()\n",
    "\n",
    "test_df['RSI_10day_ma'] = test_df['RSI'].rolling(window=10).mean()\n",
    "\n",
    "\n",
    "# Calculate Price Rate of Change (ROC)\n",
    "train_df['ROC_5day'] = momentum.roc(train_df['Close'], window=5)\n",
    "train_df['ROC_10day'] = momentum.roc(train_df['Close'], window=10)\n",
    "\n",
    "test_df['ROC_5day'] = momentum.roc(test_df['Close'], window=5)\n",
    "test_df['ROC_10day'] = momentum.roc(test_df['Close'], window=10)\n",
    "\n",
    "# Calculate 10-day moving average of ROC\n",
    "train_df['ROC_10day_ma'] = train_df['ROC_10day'].rolling(window=10).mean()\n",
    "\n",
    "test_df['ROC_10day_ma'] = test_df['ROC_10day'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate 10-day moving average of MACD\n",
    "train_df['MACD_10day_ma'] = train_df['MACD'].rolling(window=10).mean()\n",
    "\n",
    "test_df['MACD_10day_ma'] = test_df['MACD'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate 10-day moving average of CCI\n",
    "train_df['CCI_10day_ma'] = train_df['CCI'].rolling(window=10).mean()\n",
    "\n",
    "test_df['CCI_10day_ma'] = test_df['CCI'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate 10-day moving average of ADX\n",
    "train_df['ADX_10day_ma'] = train_df['ADX'].rolling(window=10).mean()\n",
    "\n",
    "test_df['ADX_10day_ma'] = test_df['ADX'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate awesome oscillator\n",
    "ao = momentum.AwesomeOscillatorIndicator(train_df['High'], train_df['Low'], window1=5, window2=34)\n",
    "train_df['AO'] = ao.awesome_oscillator()\n",
    "\n",
    "ao = momentum.AwesomeOscillatorIndicator(test_df['High'], test_df['Low'], window1=5, window2=34)\n",
    "test_df['AO'] = ao.awesome_oscillator()\n",
    "\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "# Normalize volume\n",
    "scaler = MinMaxScaler()\n",
    "train_df['Volume'] = scaler.fit_transform(train_df[['Volume']])\n",
    "test_df['Volume'] = scaler.transform(test_df[['Volume']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide train_df into train and validation\n",
    "# We will use 80% of the data for training and 20% for validation\n",
    "\n",
    "train, validation = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = train.drop(['label'], axis=1)\n",
    "train_labels = train['label']\n",
    "\n",
    "validation_features = validation.drop(['label'], axis=1)\n",
    "validation_labels = validation['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=300, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=300, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=300, random_state=42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un modelo de Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "rf_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distributions to search over\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(5, 20),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# Create a Random Forest regressor object\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Create a RandomizedSearchCV object and fit it to the data\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, cv=5, n_iter=5)\n",
    "random_search.fit(train_features, train_labels)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean squared error\n",
    "print('Best hyperparameters:', random_search.best_params_)\n",
    "print('Mean squared error:', random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo de regresión logística\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "lr_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_features.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features, train_labels, epochs=200, batch_size=32, validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.6892307692307692\n",
      "Recuperación:  0.6956521739130435\n",
      "Puntuación F1:  0.6892307692307692\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones sobre los datos de prueba\n",
    "test_predictions = rf_model.predict(validation_features)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(validation_labels, test_predictions)\n",
    "recall = recall_score(validation_labels, test_predictions)\n",
    "f1 = f1_score(validation_labels, test_predictions)\n",
    "\n",
    "print('Precisión: ', accuracy)\n",
    "print('Recuperación: ', recall)\n",
    "print('Puntuación F1: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predcciones sobre los datos de test\n",
    "test_set_predictions = rf_model.predict(test_df)\n",
    "\n",
    "# Create JSON file with predictions\n",
    "# Create a dictionary with the predictions\n",
    "predictions_dict = {}\n",
    "for i in range(0, len(test_set_predictions)):\n",
    "    predictions_dict[str(i)] = (int)(test_set_predictions[i])\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('predictions.json', 'w') as f:\n",
    "    json.dump(predictions_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
